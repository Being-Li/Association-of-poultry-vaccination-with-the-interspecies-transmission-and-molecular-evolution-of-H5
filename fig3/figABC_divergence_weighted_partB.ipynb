{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "317d4c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import string\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import AlignIO\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from Bio.Align import AlignInfo\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "#Kappa is estimated by BEAST and can be found in the .log file within seasonal-cov/beast/cov/gene/\n",
    "#For each CoV, kappa is the average of the kappa values estimated for the spike and rdrp trees \n",
    "def weight_by_kappa(start_nt, mut_nt, codon_pos, cov, lineage):\n",
    "    if lineage!=None:\n",
    "        cov_lineage = cov+lineage\n",
    "    else:\n",
    "        cov_lineage = cov\n",
    "\n",
    "    kappa_values = {'Bangladesh':{'kappa12': 9.021, 'kappa3': 15.588},\n",
    "                    'IndonesiaL1':{'kappa12': 8.384, 'kappa3': 12.666},\n",
    "                    'IndonesiaL2':{'kappa12': 5.404, 'kappa3': 15.46},\n",
    "                    'ChinaBranch_ysub3':{'kappa12': 6.101, 'kappa3': 12.66}\n",
    "                   }\n",
    "    \n",
    "    if codon_pos == 2:\n",
    "        kappa = kappa_values[cov_lineage]['kappa3']\n",
    "        #kappa=weight_tv/weight_ti\n",
    "        #weight_ti+weight_tv=1\n",
    "        weight_tv = 1/(1+kappa)\n",
    "        weight_ti = 1-weight_tv\n",
    "    else:\n",
    "        kappa = kappa_values[cov_lineage]['kappa12']\n",
    "        weight_tv = 1/(1+kappa)\n",
    "        weight_ti = 1-weight_tv\n",
    "    \n",
    "    transitions = {'T': 'C', 'C':'T', 'A':'G', 'G':'A'}\n",
    "    \n",
    "    if mut_nt == transitions[start_nt]:\n",
    "        return(weight_ti)\n",
    "    else:\n",
    "        return(weight_tv)\n",
    "\n",
    "#iterate through all possible mutations and tally how many would be syn vs nonsyn\n",
    "def find_nonsyn_syn_denominators(seq, aa_seq, cov, lineage):\n",
    "    \n",
    "    seq = str(seq)\n",
    "    aa_seq = str(aa_seq)\n",
    "    \n",
    "    nonsyn_denominator = 0\n",
    "    syn_denominator = 0\n",
    "    \n",
    "    all_nts = ['A', 'C', 'G', 'T']\n",
    "    \n",
    "    for pos in range(len(seq)):\n",
    "        nt = seq[pos]\n",
    "        if nt!='N':\n",
    "\n",
    "            codon = math.floor(pos/3)\n",
    "            codon_pos = pos-(codon*3)\n",
    "            real_codon_aa = aa_seq[codon]\n",
    "\n",
    "            all_other_nts = [x for x in all_nts if x != nt]\n",
    "            for mutated_nt in all_other_nts: \n",
    "                if codon_pos == 0:\n",
    "                    mut_codon_nt = mutated_nt+seq[pos+1:(pos+3)]\n",
    "                elif codon_pos == 1:\n",
    "                    mut_codon_nt = seq[pos-1]+mutated_nt+seq[pos+1]\n",
    "                elif codon_pos == 2:\n",
    "                    mut_codon_nt = seq[(pos-2):pos]+mutated_nt\n",
    "\n",
    "                mut_codon_aa = Seq(mut_codon_nt).translate()\n",
    "\n",
    "                if mut_codon_aa!=real_codon_aa:\n",
    "                    nonsyn_denominator+=weight_by_kappa(nt, mutated_nt, codon_pos, cov, lineage)\n",
    "                elif mut_codon_aa==real_codon_aa:\n",
    "                    syn_denominator+=weight_by_kappa(nt, mutated_nt, codon_pos, cov, lineage)\n",
    "\n",
    "        \n",
    "    return(nonsyn_denominator, syn_denominator)\n",
    "\n",
    "def find_founder_consensus(virus_time_subset,input_file_alignment, min_seqs):\n",
    "    \n",
    "    #strains at first time point(to make consensus from)\n",
    "    first_window = True\n",
    "    first_window_strains = []\n",
    "    first_window_sequences = []\n",
    "    first_window_years = ''\n",
    "    root_seq = ''\n",
    "    root_aa_seq = ''\n",
    "    \n",
    "    for years, subset_viruses in virus_time_subset.items():\n",
    "    #don't use windows with fewer than min_seqs \n",
    "        if len(subset_viruses) >= min_seqs:\n",
    "\n",
    "\n",
    "            #make consensus sequence at first time point\n",
    "            if first_window == True:\n",
    "                first_window_years = years\n",
    "                first_window_strains+=subset_viruses\n",
    "                with open(input_file_alignment, \"r\") as aligned_handle:\n",
    "                    for virus in SeqIO.parse(aligned_handle, \"fasta\"):\n",
    "                        if virus.id in first_window_strains:\n",
    "                            first_window_sequences.append(virus)\n",
    "\n",
    "                first_window_alignment = MultipleSeqAlignment(first_window_sequences)\n",
    "                root_seq = AlignInfo.SummaryInfo(first_window_alignment).dumb_consensus(ambiguous ='N')\n",
    "                root_aa_seq = root_seq.translate()\n",
    "\n",
    "                first_window = False\n",
    "    \n",
    "    return(root_seq, root_aa_seq, first_window_years)\n",
    "\n",
    "def divergence_weighted(cov, gene, window, clade, min_seqs, year_max=None, year_min=None):\n",
    "    #Find fraction of sites that differ from root and average among all viruses at each time point\n",
    "    #input_file_root = '/home/wb/lby/eLife/data/change/change_ref_ref_KP732638.1/'+str(cov)+'_'+str(gene)+'_root-sequence.json'\n",
    "    input_file_alignment = '/home/wb/lby/eLife/data/change/AF144305/'+str(cov)+'_'+str(gene)+'.fasta'\n",
    "    metafile = '/home/wb/lby/eLife/data/change/AF144305/'+str(cov)+'_'+str(gene)+'_metadata.tsv'\n",
    "    \n",
    "    #Subset data based on time windows\n",
    "    meta = pd.read_csv(metafile, sep = '\\t')\n",
    "    meta.drop(meta[meta['date']=='?'].index, inplace=True)\n",
    "    meta.dropna(subset=['date'], inplace=True)\n",
    "    meta['year'] = meta['date'].str[:4].astype('int')\n",
    "    \n",
    "    if year_max:\n",
    "        meta.drop(meta[meta['year']>year_max].index, inplace=True)\n",
    "    if year_min:\n",
    "        meta.drop(meta[meta['year']<year_min].index, inplace=True)\n",
    "    \n",
    "    #Remove HKU1 and NL63 outgroup (that was used to root)\n",
    "    #meta.drop(meta[meta['strain']=='hku14_3/JN874560/HKU1/china/2007'].index, inplace=True)\n",
    "    #meta.drop(meta[meta['strain']=='mhv/NC_048217_1/mhv/2006'].index, inplace=True)\n",
    "    #meta.drop(meta[meta['strain']=='229e/AF304460/229e_ref/Germany/2000'].index, inplace=True)\n",
    "    \n",
    "    date_range = meta['year'].max() - meta['year'].min()\n",
    "    \n",
    "    #Group viruses by time windows\n",
    "    virus_time_subset = {}\n",
    "    if window == 'all':\n",
    "        years = str(meta['year'].min()) + '-' + str(meta['year'].max())\n",
    "        virus_time_subset[years] = meta['strain'].tolist()\n",
    "    else:\n",
    "        date_window_start = meta['year'].min()\n",
    "        date_window_end = meta['year'].min() + window\n",
    "        while date_window_end <= meta['year'].max():\n",
    "            years = str(date_window_start) + '-' + str(date_window_end)\n",
    "            strains = meta[(meta['year']>=date_window_start) & (meta['year']<date_window_end)]['strain'].tolist()\n",
    "            virus_time_subset[years] = strains\n",
    "            #sliding window\n",
    "            date_window_end += 1\n",
    "            date_window_start += 1     \n",
    "    \n",
    "    root_seq, root_aa_seq, first_window_years = find_founder_consensus(virus_time_subset,input_file_alignment, min_seqs)\n",
    "    \n",
    "    nonsyn_denominator, syn_denominator = find_nonsyn_syn_denominators(root_seq, root_aa_seq, cov, clade)\n",
    "\n",
    "    \n",
    "    #initiate lists to record all time windows\n",
    "    year_windows = []\n",
    "    seqs_in_window = []\n",
    "    nonsyn_divergences = []\n",
    "    syn_divergences = []\n",
    "    nonsyn_divergences_window_average = []\n",
    "    syn_divergences_window_average = []\n",
    "\n",
    "    \n",
    "    for years, subset_viruses in virus_time_subset.items():\n",
    "    #don't use windows with fewer than min_seqs \n",
    "        if len(subset_viruses) >= min_seqs:\n",
    "            year_windows.append(years)\n",
    "            seqs_in_window.append(len(subset_viruses))\n",
    "            \n",
    "\n",
    "            syn_div_allviruses_in_window = []\n",
    "            nonsyn_div_allviruses_in_window  = []\n",
    "            with open(input_file_alignment, \"r\") as aligned_handle:\n",
    "                for virus in SeqIO.parse(aligned_handle, \"fasta\"):         \n",
    "                    #Only viruses in time window\n",
    "                    if virus.id in subset_viruses:    \n",
    "                        #check\n",
    "                        if len(virus.seq) != len(root_seq):\n",
    "                            print(virus)\n",
    "                        elif len(virus.seq) == len(root_seq):\n",
    "                            count_total_unambiguous = 0\n",
    "                            count_subs = 0\n",
    "                            count_syn_subs = 0\n",
    "                            count_nonsyn_subs = 0\n",
    "                            for pos in range(len(root_seq)):\n",
    "                                root_nt = str(root_seq[pos])\n",
    "                                virus_nt = str(virus.seq[pos])\n",
    "                                #skip ambiguous sites\n",
    "                                if virus_nt != 'N':\n",
    "                                    if root_nt != 'N':\n",
    "                                        count_total_unambiguous+=1\n",
    "                                        if virus_nt != root_nt:\n",
    "                                            count_subs+=1\n",
    "                                            #determine syn or nonsyn\n",
    "                                            codon = math.floor(pos/3)\n",
    "                                            codon_pos = pos-(codon*3)\n",
    "                                            if codon_pos == 0:\n",
    "                                                codon_nt = virus.seq[pos:(pos+3)]\n",
    "                                            elif codon_pos == 1:\n",
    "                                                codon_nt = virus.seq[(pos-1):(pos+2)]\n",
    "                                            elif codon_pos == 2:\n",
    "                                                codon_nt = virus.seq[(pos-2):(pos+1)]\n",
    "                                            codon_aa = codon_nt.translate()\n",
    "                                            root_aa = root_aa_seq[codon]\n",
    "                                            #skip ambiguous\n",
    "                                            if root_aa != 'X':\n",
    "                                                if codon_aa != root_aa:\n",
    "                                                    count_nonsyn_subs+=1\n",
    "                                                elif codon_aa == root_aa:\n",
    "                                                    count_syn_subs+=1\n",
    "\n",
    "\n",
    "                            #Multiply div by fraction of sites that were unambiguously sequenced\n",
    "                            unambiguous_ratio = count_total_unambiguous/len(root_seq)\n",
    "                            syn_div_for_virus = (count_syn_subs*unambiguous_ratio)/(syn_denominator*unambiguous_ratio)\n",
    "#                             syn_div_for_virus = (count_syn_subs)/(syn_denominator)\n",
    "                            syn_div_allviruses_in_window.append(syn_div_for_virus)\n",
    "                            nonsyn_div_for_virus = (count_nonsyn_subs*unambiguous_ratio)/(nonsyn_denominator*unambiguous_ratio)\n",
    "#                             nonsyn_div_for_virus = (count_nonsyn_subs)/(nonsyn_denominator)\n",
    "                            nonsyn_div_allviruses_in_window.append(nonsyn_div_for_virus)\n",
    "\n",
    "\n",
    "\n",
    "                mean_syn_div_in_window = sum(syn_div_allviruses_in_window)/len(syn_div_allviruses_in_window)\n",
    "                mean_nonsyn_div_in_window = sum(nonsyn_div_allviruses_in_window)/len(nonsyn_div_allviruses_in_window)\n",
    "\n",
    "                syn_divergences.append(syn_div_allviruses_in_window)\n",
    "                nonsyn_divergences.append(nonsyn_div_allviruses_in_window)\n",
    "\n",
    "                syn_divergences_window_average.append(mean_syn_div_in_window)\n",
    "                nonsyn_divergences_window_average.append(mean_nonsyn_div_in_window)\n",
    "\n",
    "            \n",
    "    return year_windows, seqs_in_window, syn_divergences, nonsyn_divergences, syn_divergences_window_average, nonsyn_divergences_window_average\n",
    "\n",
    "\n",
    "def plot_divergence_weighted(covs, genes, window, min_seqs, year_max=None, year_min=None, filename=None):\n",
    "    \n",
    "    data_to_plot = []\n",
    "    \n",
    "    #cov_clades = {'229e': [None], 'oc43': ['A', 'B'], 'nl63': [None], 'hku1': [None]}\n",
    "    cov_clades = {'Bangladesh':[None],'IndonesiaL1':[None],'IndonesiaL2':[None],'ChinaBranch_ysub3':[None]}\n",
    "#     cov_clades = {'229e': [None], 'oc43': ['A', 'B'], 'nl63': [None], 'hku1': ['A', 'B']}\n",
    "    \n",
    "    for cov in covs:\n",
    "        clades = cov_clades[cov]\n",
    "        for clade in clades:\n",
    "            for gene in genes:\n",
    "                year_windows, seqs_in_window, syn_divergences, nonsyn_divergences, syn_divergences_window_average, nonsyn_divergences_window_average= divergence_weighted(cov, gene, window, clade, min_seqs, year_max, year_min)\n",
    "\n",
    "                for window_index in range(len(year_windows)):\n",
    "                    if clade == None:\n",
    "                        cov_clade = str(cov).upper()\n",
    "                    elif clade != None:\n",
    "                        cov_clade = str(cov).upper()+\" lineage \"+str(clade)\n",
    "                    for virus_syn in syn_divergences[window_index]:\n",
    "                        data_to_plot.append({'year': year_windows[window_index][0:4], \n",
    "                                             'gene': gene, 'substitution': 'syn', \n",
    "                                             'divergence': virus_syn, 'cov': cov, 'cov_clade': cov_clade})\n",
    "                    for virus_nonsyn in nonsyn_divergences[window_index]:\n",
    "                        data_to_plot.append({'year': year_windows[window_index][0:4], \n",
    "                             'gene': gene, 'substitution': 'nonsyn', \n",
    "                             'divergence': virus_nonsyn, 'cov': cov, 'cov_clade': cov_clade})\n",
    "\n",
    "    df_to_plot = pd.DataFrame(data_to_plot)\n",
    "    df_to_plot['year'] = df_to_plot['year'].astype('int')\n",
    "    df_to_plot.to_csv(\"test.csv\", index=False)\n",
    "    \n",
    "    \n",
    "#     color_map = {'replicase1ab': '#CB4335', 'rdrp': '#CB4335', \n",
    "#                  'spike': '#009888', 's1': '#87C735', 's2': '#526EFF', \n",
    "#                  'membrane': '#FF9A00', 'envelope': '#FFCD00', 'nucleoprotein': '#7F4FC9'}\n",
    "    \n",
    "#     color_map = {'rdrp':'#000000', 'spike': '#858585', 's1': '#cccccc', 's2': '#5c5c5c'}\n",
    "    #color_map = {'rdrp':'#5c5c5c', 'spike': '#ff7400', 's1': '#ff9a00', 's2': '#858585'}\n",
    "    color_map = {'ha':'#5c5c5c'}\n",
    "    \n",
    "\n",
    "\n",
    "    sns.set(font_scale=2)\n",
    "    #sns.set_style(\"white\")\n",
    "    sns.set_style(\"ticks\")\n",
    "#     sns.set_context(rc={\"legend.fontsize\":24})\n",
    "    plt.rcParams[\"legend.markerscale\"] = 3.0\n",
    "    plt.rcParams['lines.linewidth'] = 6\n",
    "\n",
    "    \n",
    "    g = sns.relplot(x='year', y='divergence', hue='gene', style = 'substitution', palette = color_map,\n",
    "                    col='cov_clade', col_wrap=3, kind = 'line', legend = 'full', \n",
    "                    facet_kws=dict(sharex=False, sharey=True), \n",
    "                    height=4, aspect=1.5, ci=95, \n",
    "#                     err_style=\"bars\", err_kws={'elinewidth':2},\n",
    "#                     markers = True, markersize = 12, \n",
    "                    data = df_to_plot).set_titles(\"{col_name}\", fontweight='bold')\n",
    "    \n",
    "    for ax in g.axes.flat:\n",
    "        ax.set_xlabel('')\n",
    "        ax.minorticks_on()\n",
    "        ax.grid(which='minor', axis='both')\n",
    "        ax.grid(which='major', axis='both')\n",
    "        #for fig 3:\n",
    "#         ax.set_ylim(0, 0.035)\n",
    "        \n",
    "        #for supp:\n",
    "        ax.set_ylim(0, 0.2)\n",
    "        #for fig 3:\n",
    "#         ax.set_xlim(1980, 2018)\n",
    "        #for supp:\n",
    "    \n",
    "        ax.set_xlim(1996, 2024)\n",
    "    \n",
    "    if filename:\n",
    "        g.savefig(filename, bbox_inches='tight', dpi=300, format='svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2e66840",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/wb/lby/eLife/data/change/AF144305/ChinaBranch_ysub3_ha_metadata.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0e7cedbef1df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_divergence_weighted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Bangladesh'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'IndonesiaL1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'IndonesiaL2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ChinaBranch_ysub3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ha'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1996\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test.svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-fa63758e5101>\u001b[0m in \u001b[0;36mplot_divergence_weighted\u001b[0;34m(covs, genes, window, min_seqs, year_max, year_min, filename)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mclade\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclades\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mgene\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                 \u001b[0myear_windows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs_in_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn_divergences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonsyn_divergences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn_divergences_window_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonsyn_divergences_window_average\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdivergence_weighted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclade\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mwindow_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear_windows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-fa63758e5101>\u001b[0m in \u001b[0;36mdivergence_weighted\u001b[0;34m(cov, gene, window, clade, min_seqs, year_max, year_min)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;31m#Subset data based on time windows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetafile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'?'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geo/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geo/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geo/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geo/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geo/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/wb/lby/eLife/data/change/AF144305/ChinaBranch_ysub3_ha_metadata.tsv'"
     ]
    }
   ],
   "source": [
    "plot_divergence_weighted(['Bangladesh','IndonesiaL1','IndonesiaL2','ChinaBranch_ysub3'], ['ha'], 1, 2, year_min=1996, filename='test.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdc9ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3692ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
